# Data Detective ETL

Powered by data-detective-airflow framework.

Filling the Data Detective repository with demo data.

## Development

The development environment runs in Docker containers on the developer machine.
It is possible to run commands inside a container.
You can connect via the `docker-compose exec app bash` command or ssh to port 9922 on localhost. 
An ssh connection allows running tests from PyCharm Professional via an ssh interpreter.

Before starting docker-compose, generate a `.env` file in the same way as` .env.example`.
```shell
cd data-detective-etl
cp .env.example .env
randstr=`shuf -zer -n32  {A..Z} {a..z} {0..9} | tr -d '\0'`
echo "AIRFLOW__WEBSERVER__SECRET_KEY=${randstr}" >> .env
```
* Run the sandbox with docker-compose `docker-compose up -d`
* Run tests: `make tests`
* Run linters: `make lint`

## Root hierarchy

`The table and tree are generated by the common/root_tree_generator.py script`

Here are the service objects of the hierarchy.
Real metadata objects associated with them.
```
root
├── Documentation
└── Data Detective
	├── Logical Model
	├── Physical Model
	└── DAGs
```
