version: '2.3'

x-airflow: &airflow
  build:
    context: .
    target: dev
  environment:
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${META_USER}:${META_PASS}@metadb:5432/${META_USER}
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__WEBSERVER__SECRET_KEY=${SECRET_KEY}
    - AIRFLOW__DATABASE__LOAD_DEFAULT_CONNECTIONS=False
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - PYTHON_VERSION=${PYTHON_VERSION}
    - POETRY_VERSION=${POETRY_VERSION}

services:
  ssh_service:
    build:
      context: docker/ssh_service
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 22"]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 20s

  metadb:
    image: postgres:13.4-alpine
    environment:
      - POSTGRES_USER=${META_USER}
      - POSTGRES_PASSWORD=${META_PASS}
    ports:
      - "5004:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 16s
      timeout: 5s
      retries: 10
      start_period: 20s

  pg:
    image: postgres:13.4-alpine
    environment:
      - POSTGRES_USER=${META_USER}
      - POSTGRES_PASSWORD=${META_PASS}
    volumes:
      - ./docker/init-pg.sql:/docker-entrypoint-initdb.d/init-pg.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 17s
      timeout: 5s
      retries: 10
      start_period: 20s

  s3:
    image: localstack/localstack:1.0.4
    environment:
      - EAGER_SERVICE_LOADING=1
      - SERVICES=s3
      - DEBUG=0
      # Disable LocalStack Event Analytics
      - DISABLE_EVENTS=1
    volumes:
      - ./docker/init-s3.sh:/docker-entrypoint-initaws.d/init-s3.sh
    healthcheck:
      test: bash -c -l 'AWS_ACCESS_KEY_ID=fake AWS_SECRET_ACCESS_KEY=fake aws --endpoint-url=http://localhost:4566 s3 ls'
      interval: 18s
      timeout: 5s
      retries: 10
      start_period: 20s

  tests:
    <<: *airflow
    depends_on:
      ssh_service:
        condition: service_healthy
      metadb:
        condition: service_healthy
      pg:
        condition: service_healthy
      s3:
        condition: service_healthy
    ports:
      - "8080:8080"
    volumes:
      - ./dags:${AIRFLOW_HOME}/dags
      - ./data_detective_airflow:${AIRFLOW_HOME}/data_detective_airflow
      - ./tests:${AIRFLOW_HOME}/tests
      - ./tests_data:${AIRFLOW_HOME}/tests_data
      - ./Makefile:${AIRFLOW_HOME}/Makefile
      - ./pyproject.toml:${AIRFLOW_HOME}/pyproject.toml
      - ./setup.cfg:${AIRFLOW_HOME}/setup.cfg
    command: tests
