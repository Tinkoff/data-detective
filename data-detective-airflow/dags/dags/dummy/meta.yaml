description: Example of a DAG for debugging and testing
schedule_interval:
default_args:
  owner: airflow
  retries: 1
  retry_delay: 2
  result_type: pickle
  work_type: s3
  work_conn_id: s3
factory: YAML
tasks:
- task_id: df_now1
  description: Database Query
  type: data_detective_airflow.operators.extractors.DBDump
  conn_id: pg
  sql: select * from test1;
- task_id: df_now2
  description: Database Query
  type: data_detective_airflow.operators.extractors.DBDump
  conn_id: pg
  sql: select * from test1;
- task_id: transform
  type: data_detective_airflow.operators.transformers.PyTransform
  source:
  - df_now2
  transformer_callable: val_translate
  op_kwargs:
    file_name: val_translation.yaml
- task_id: append_all
  description: Merging the previous result with itself
  type: data_detective_airflow.operators.transformers.PyTransform
  source:
  - df_now1
  - transform
  transformer_callable: >
    lambda _context, df_now1, transform: df_now1.append(transform, sort=False)
- task_id: sink
  description: Write the result
  type: data_detective_airflow.operators.sinks.PgSCD1
  source:
  - append_all
  conn_id: pg
  key:
  - test
  table_name: test2
  logging_thread_flg: No
